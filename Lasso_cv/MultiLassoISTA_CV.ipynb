{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6u7ZcNnILatJnxRvtS8vC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Q3QcoSLlj5E","executionInfo":{"status":"ok","timestamp":1669893905897,"user_tz":-120,"elapsed":3,"user":{"displayName":"hua Yu","userId":"12257416468269475765"}},"outputId":"8d11d5fb-bcb1-45d3-8133-8a1153e00335"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec  1 11:25:05 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   61C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/lasso_cv_ista')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-7ZSltkl-Yw","executionInfo":{"status":"ok","timestamp":1669893931352,"user_tz":-120,"elapsed":20198,"user":{"displayName":"hua Yu","userId":"12257416468269475765"}},"outputId":"889ab3a9-9321-43f7-a607-201aa98a262f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!python cv.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jo0NlA3WmB14","outputId":"5476a866-7ee8-49b9-d378-70929e444f53","executionInfo":{"status":"ok","timestamp":1669896114058,"user_tz":-120,"elapsed":2162761,"user":{"displayName":"hua Yu","userId":"12257416468269475765"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","\n","model(lambda_700_fold_10_3th.npz) starts training.\n","\n","iters=100,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 5.71 sec\n","iters=200,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.00 sec\n","iters=300,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 8.29 sec\n","iters=400,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.59 sec\n","iters=500,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.88 sec\n","iters=600,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.18 sec\n","iters=700,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 13.49 sec\n","iters=800,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.79 sec\n","iters=900,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 16.09 sec\n","iters=1000,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.40 sec\n","iters=1100,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 18.70 sec\n","iters=1200,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.01 sec\n","iters=1300,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 21.32 sec\n","iters=1400,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.62 sec\n","iters=1500,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 23.94 sec\n","iters=1600,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.25 sec\n","iters=1700,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.56 sec\n","iters=1800,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.87 sec\n","iters=1900,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.19 sec\n","iters=2000,loss=1771.670166015625,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 30.51 sec\n","----------\n","\ttraining_time=30.51 sec\n","\tepochs=2000\n","\tfinal_loss=1771.670166015625\n","\tfinal_training_mse=[1.4368147  0.97855014]\n","\tfinal_training_mae=[1.0141376 0.9869203]\n","\tfinal_validating_mse=[1.313506  0.9719739]\n","\tfinal_validating_mae=[1.0193948 0.9840261]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","\n","model(lambda_700_fold_10_4th.npz) starts training.\n","\n","iters=100,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 4.58 sec\n","iters=200,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 5.91 sec\n","iters=300,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.24 sec\n","iters=400,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 8.57 sec\n","iters=500,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.91 sec\n","iters=600,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 11.24 sec\n","iters=700,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.57 sec\n","iters=800,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 13.90 sec\n","iters=900,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.23 sec\n","iters=1000,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 16.57 sec\n","iters=1100,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.90 sec\n","iters=1200,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.24 sec\n","iters=1300,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.58 sec\n","iters=1400,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 21.92 sec\n","iters=1500,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 23.27 sec\n","iters=1600,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.62 sec\n","iters=1700,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.97 sec\n","iters=1800,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.32 sec\n","iters=1900,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 28.68 sec\n","iters=2000,loss=1775.219970703125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 30.03 sec\n","----------\n","\ttraining_time=30.03 sec\n","\tepochs=2000\n","\tfinal_loss=1775.219970703125\n","\tfinal_training_mse=[1.4427124  0.97749215]\n","\tfinal_training_mae=[1.0225171  0.98643315]\n","\tfinal_validating_mse=[1.2604275 0.9814948]\n","\tfinal_validating_mae=[0.94397944 0.98841023]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","\n","model(lambda_700_fold_10_5th.npz) starts training.\n","\n","iters=100,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 4.66 sec\n","iters=200,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 6.02 sec\n","iters=300,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.37 sec\n","iters=400,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 8.73 sec\n","iters=500,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.08 sec\n","iters=600,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 11.43 sec\n","iters=700,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.80 sec\n","iters=800,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.15 sec\n","iters=900,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.50 sec\n","iters=1000,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 16.86 sec\n","iters=1100,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 18.22 sec\n","iters=1200,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.58 sec\n","iters=1300,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.93 sec\n","iters=1400,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.29 sec\n","iters=1500,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 23.65 sec\n","iters=1600,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.00 sec\n","iters=1700,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.35 sec\n","iters=1800,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.71 sec\n","iters=1900,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.06 sec\n","iters=2000,loss=1776.499267578125,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 30.41 sec\n","----------\n","\ttraining_time=30.41 sec\n","\tepochs=2000\n","\tfinal_loss=1776.499267578125\n","\tfinal_training_mse=[1.4438303  0.97811824]\n","\tfinal_training_mae=[1.020405  0.9867773]\n","\tfinal_validating_mse=[1.2503674  0.97586083]\n","\tfinal_validating_mae=[0.96298784 0.9853125 ]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","\n","model(lambda_700_fold_10_6th.npz) starts training.\n","\n","iters=100,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 4.73 sec\n","iters=200,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 6.06 sec\n","iters=300,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.40 sec\n","iters=400,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 8.74 sec\n","iters=500,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.07 sec\n","iters=600,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 11.41 sec\n","iters=700,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.76 sec\n","iters=800,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.09 sec\n","iters=900,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.43 sec\n","iters=1000,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 16.76 sec\n","iters=1100,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 18.11 sec\n","iters=1200,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.46 sec\n","iters=1300,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.81 sec\n","iters=1400,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.15 sec\n","iters=1500,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 23.49 sec\n","iters=1600,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.84 sec\n","iters=1700,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.19 sec\n","iters=1800,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.54 sec\n","iters=1900,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 28.89 sec\n","iters=2000,loss=1755.3280029296875,lr=0.2,line search 0.01 sec,iteration 0.01 sec. Elapsed 30.24 sec\n","----------\n","\ttraining_time=30.24 sec\n","\tepochs=2000\n","\tfinal_loss=1755.3280029296875\n","\tfinal_training_mse=[1.4155477  0.97753745]\n","\tfinal_training_mae=[1.0141672  0.98646945]\n","\tfinal_validating_mse=[1.5049099 0.9810873]\n","\tfinal_validating_mae=[1.0191294 0.9880839]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","10.12 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(1/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","\n","model(lambda_700_fold_10_7th.npz) starts training.\n","\n","iters=100,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.71 sec\n","iters=200,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.44 sec\n","iters=300,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.19 sec\n","iters=400,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.95 sec\n","iters=500,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.73 sec\n","iters=600,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.52 sec\n","iters=700,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.34 sec\n","iters=800,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 28.18 sec\n","iters=900,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 31.05 sec\n","iters=1000,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.93 sec\n","iters=1100,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.81 sec\n","iters=1200,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.70 sec\n","iters=1300,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.59 sec\n","iters=1400,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 45.46 sec\n","iters=1500,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 48.31 sec\n","iters=1600,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 51.14 sec\n","iters=1700,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.96 sec\n","iters=1800,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.76 sec\n","iters=1900,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.55 sec\n","iters=2000,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 62.33 sec\n","----------\n","\ttraining_time=62.33 sec\n","\tepochs=2000\n","\tfinal_loss=1757.3502057212665\n","\tfinal_training_mse=[1.41783184 0.9780103 ]\n","\tfinal_training_mae=[1.01050726 0.98665788]\n","\tfinal_validating_mse=[1.48435245 0.97683185]\n","\tfinal_validating_mae=[1.05206754 0.98638772]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.01 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(2/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","\n","model(lambda_700_fold_10_8th.npz) starts training.\n","\n","iters=100,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.64 sec\n","iters=200,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.35 sec\n","iters=300,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.06 sec\n","iters=400,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.78 sec\n","iters=500,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.52 sec\n","iters=600,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.27 sec\n","iters=700,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.03 sec\n","iters=800,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.80 sec\n","iters=900,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.59 sec\n","iters=1000,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.40 sec\n","iters=1100,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.22 sec\n","iters=1200,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.06 sec\n","iters=1300,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.92 sec\n","iters=1400,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.80 sec\n","iters=1500,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.68 sec\n","iters=1600,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.56 sec\n","iters=1700,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.43 sec\n","iters=1800,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.28 sec\n","iters=1900,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.11 sec\n","iters=2000,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.92 sec\n","----------\n","\ttraining_time=61.92 sec\n","\tepochs=2000\n","\tfinal_loss=1750.037307968542\n","\tfinal_training_mse=[1.4084372  0.97743507]\n","\tfinal_training_mae=[1.01034677 0.98643271]\n","\tfinal_validating_mse=[1.56890422 0.98200889]\n","\tfinal_validating_mae=[1.05351191 0.98841423]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.13 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(3/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","\n","model(lambda_700_fold_10_9th.npz) starts training.\n","\n","iters=100,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.70 sec\n","iters=200,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.42 sec\n","iters=300,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.13 sec\n","iters=400,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.86 sec\n","iters=500,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.60 sec\n","iters=600,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.37 sec\n","iters=700,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.14 sec\n","iters=800,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.93 sec\n","iters=900,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.74 sec\n","iters=1000,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.55 sec\n","iters=1100,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.39 sec\n","iters=1200,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.24 sec\n","iters=1300,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.12 sec\n","iters=1400,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 45.00 sec\n","iters=1500,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.88 sec\n","iters=1600,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.76 sec\n","iters=1700,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.63 sec\n","iters=1800,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.47 sec\n","iters=1900,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.30 sec\n","iters=2000,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 62.12 sec\n","----------\n","\ttraining_time=62.12 sec\n","\tepochs=2000\n","\tfinal_loss=1750.3193000112592\n","\tfinal_training_mse=[1.40857078 0.97768593]\n","\tfinal_training_mae=[1.0089599  0.98648569]\n","\tfinal_validating_mse=[1.56770195 0.97975113]\n","\tfinal_validating_mae=[1.06599383 0.98793735]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.03 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(4/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","\n","model(lambda_700_fold_10_10th.npz) starts training.\n","\n","iters=100,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.68 sec\n","iters=200,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.39 sec\n","iters=300,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.11 sec\n","iters=400,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.84 sec\n","iters=500,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.59 sec\n","iters=600,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.35 sec\n","iters=700,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.12 sec\n","iters=800,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.91 sec\n","iters=900,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.71 sec\n","iters=1000,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.53 sec\n","iters=1100,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.37 sec\n","iters=1200,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.23 sec\n","iters=1300,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.10 sec\n","iters=1400,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.98 sec\n","iters=1500,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.86 sec\n","iters=1600,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.74 sec\n","iters=1700,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.59 sec\n","iters=1800,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.43 sec\n","iters=1900,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.25 sec\n","iters=2000,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 62.06 sec\n","----------\n","\ttraining_time=62.06 sec\n","\tepochs=2000\n","\tfinal_loss=1770.4119888788382\n","\tfinal_training_mse=[1.43713451 0.9765151 ]\n","\tfinal_training_mae=[1.02019785 0.98591539]\n","\tfinal_validating_mse=[1.31062841 0.99028861]\n","\tfinal_validating_mae=[0.96485223 0.9930701 ]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.04 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(5/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_1th.npz) starts training.\n","\n","iters=100,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.62 sec\n","iters=200,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.33 sec\n","iters=300,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.04 sec\n","iters=400,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.77 sec\n","iters=500,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.52 sec\n","iters=600,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.27 sec\n","iters=700,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.03 sec\n","iters=800,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.81 sec\n","iters=900,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.61 sec\n","iters=1000,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.44 sec\n","iters=1100,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.27 sec\n","iters=1200,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.13 sec\n","iters=1300,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.00 sec\n","iters=1400,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.88 sec\n","iters=1500,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.75 sec\n","iters=1600,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.62 sec\n","iters=1700,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.47 sec\n","iters=1800,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.30 sec\n","iters=1900,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.11 sec\n","iters=2000,loss=1744.7436181653284,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.91 sec\n","----------\n","\ttraining_time=61.91 sec\n","\tepochs=2000\n","\tfinal_loss=1744.7436181653284\n","\tfinal_training_mse=[1.39947639 0.97917885]\n","\tfinal_training_mae=[1.0055203  0.98731839]\n","\tfinal_validating_mse=[1.64955149 0.96631486]\n","\tfinal_validating_mae=[1.09695016 0.98044313]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.05 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(6/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_2th.npz) starts training.\n","\n","iters=100,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.60 sec\n","iters=200,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.31 sec\n","iters=300,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.02 sec\n","iters=400,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.76 sec\n","iters=500,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.52 sec\n","iters=600,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.31 sec\n","iters=700,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.08 sec\n","iters=800,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.86 sec\n","iters=900,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.67 sec\n","iters=1000,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.50 sec\n","iters=1100,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.34 sec\n","iters=1200,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.19 sec\n","iters=1300,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.07 sec\n","iters=1400,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.03 sec. Elapsed 44.96 sec\n","iters=1500,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.84 sec\n","iters=1600,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.70 sec\n","iters=1700,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.54 sec\n","iters=1800,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.37 sec\n","iters=1900,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.18 sec\n","iters=2000,loss=1769.850782480567,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.98 sec\n","----------\n","\ttraining_time=61.98 sec\n","\tepochs=2000\n","\tfinal_loss=1769.850782480567\n","\tfinal_training_mse=[1.43448315 0.97840135]\n","\tfinal_training_mae=[1.01987408 0.98689842]\n","\tfinal_validating_mse=[1.33449066 0.97331233]\n","\tfinal_validating_mae=[0.96776614 0.98422286]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(7/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_3th.npz) starts training.\n","\n","iters=100,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.56 sec\n","iters=200,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.26 sec\n","iters=300,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 13.97 sec\n","iters=400,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.69 sec\n","iters=500,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.43 sec\n","iters=600,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.18 sec\n","iters=700,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 24.95 sec\n","iters=800,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.73 sec\n","iters=900,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.52 sec\n","iters=1000,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.33 sec\n","iters=1100,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.16 sec\n","iters=1200,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.01 sec\n","iters=1300,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.87 sec\n","iters=1400,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.75 sec\n","iters=1500,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.63 sec\n","iters=1600,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.51 sec\n","iters=1700,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.36 sec\n","iters=1800,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.20 sec\n","iters=1900,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.02 sec\n","iters=2000,loss=1771.6701099475658,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.83 sec\n","----------\n","\ttraining_time=61.83 sec\n","\tepochs=2000\n","\tfinal_loss=1771.6701099475658\n","\tfinal_training_mse=[1.43681479 0.97855005]\n","\tfinal_training_mae=[1.01413759 0.98692025]\n","\tfinal_validating_mse=[1.31350585 0.9719741 ]\n","\tfinal_validating_mae=[1.01939457 0.98402636]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.12 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(8/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_4th.npz) starts training.\n","\n","iters=100,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.54 sec\n","iters=200,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.24 sec\n","iters=300,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 13.96 sec\n","iters=400,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.69 sec\n","iters=500,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.43 sec\n","iters=600,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.18 sec\n","iters=700,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 24.95 sec\n","iters=800,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.73 sec\n","iters=900,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.52 sec\n","iters=1000,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.34 sec\n","iters=1100,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.18 sec\n","iters=1200,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.03 sec\n","iters=1300,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.90 sec\n","iters=1400,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.78 sec\n","iters=1500,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.65 sec\n","iters=1600,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.52 sec\n","iters=1700,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.36 sec\n","iters=1800,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.19 sec\n","iters=1900,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.00 sec\n","iters=2000,loss=1775.220076023776,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.82 sec\n","----------\n","\ttraining_time=61.82 sec\n","\tepochs=2000\n","\tfinal_loss=1775.220076023776\n","\tfinal_training_mse=[1.44271243 0.97749218]\n","\tfinal_training_mae=[1.02251705 0.98643315]\n","\tfinal_validating_mse=[1.26042716 0.98149493]\n","\tfinal_validating_mae=[0.94397941 0.98841025]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.07 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(9/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_5th.npz) starts training.\n","\n","iters=100,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.59 sec\n","iters=200,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.30 sec\n","iters=300,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.01 sec\n","iters=400,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.74 sec\n","iters=500,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.49 sec\n","iters=600,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.25 sec\n","iters=700,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.01 sec\n","iters=800,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.79 sec\n","iters=900,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.58 sec\n","iters=1000,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.40 sec\n","iters=1100,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.23 sec\n","iters=1200,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.08 sec\n","iters=1300,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.95 sec\n","iters=1400,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.83 sec\n","iters=1500,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.70 sec\n","iters=1600,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.56 sec\n","iters=1700,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.40 sec\n","iters=1800,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.23 sec\n","iters=1900,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.04 sec\n","iters=2000,loss=1776.4991815933558,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.84 sec\n","----------\n","\ttraining_time=61.84 sec\n","\tepochs=2000\n","\tfinal_loss=1776.4991815933558\n","\tfinal_training_mse=[1.44383021 0.97811823]\n","\tfinal_training_mae=[1.020405   0.98677733]\n","\tfinal_validating_mse=[1.25036711 0.97586043]\n","\tfinal_validating_mae=[0.96298789 0.98531263]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(10/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_6th.npz) starts training.\n","\n","iters=100,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.53 sec\n","iters=200,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.24 sec\n","iters=300,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 13.96 sec\n","iters=400,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.68 sec\n","iters=500,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.42 sec\n","iters=600,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.18 sec\n","iters=700,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 24.94 sec\n","iters=800,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.72 sec\n","iters=900,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.51 sec\n","iters=1000,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.32 sec\n","iters=1100,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.15 sec\n","iters=1200,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 38.99 sec\n","iters=1300,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.86 sec\n","iters=1400,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.74 sec\n","iters=1500,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.61 sec\n","iters=1600,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.49 sec\n","iters=1700,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.34 sec\n","iters=1800,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.18 sec\n","iters=1900,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.00 sec\n","iters=2000,loss=1755.3279651189214,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.81 sec\n","----------\n","\ttraining_time=61.81 sec\n","\tepochs=2000\n","\tfinal_loss=1755.3279651189214\n","\tfinal_training_mse=[1.4155477  0.97753746]\n","\tfinal_training_mae=[1.01416708 0.9864694 ]\n","\tfinal_validating_mse=[1.50490969 0.98108737]\n","\tfinal_validating_mae=[1.0191292  0.98808397]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(11/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_7th.npz) starts training.\n","\n","iters=100,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.60 sec\n","iters=200,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.33 sec\n","iters=300,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.08 sec\n","iters=400,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.82 sec\n","iters=500,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.56 sec\n","iters=600,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.32 sec\n","iters=700,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.09 sec\n","iters=800,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.87 sec\n","iters=900,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.67 sec\n","iters=1000,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.49 sec\n","iters=1100,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.32 sec\n","iters=1200,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.18 sec\n","iters=1300,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.06 sec\n","iters=1400,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.93 sec\n","iters=1500,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.80 sec\n","iters=1600,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.67 sec\n","iters=1700,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.51 sec\n","iters=1800,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.03 sec. Elapsed 56.34 sec\n","iters=1900,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.15 sec\n","iters=2000,loss=1757.3502057212665,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.95 sec\n","----------\n","\ttraining_time=61.95 sec\n","\tepochs=2000\n","\tfinal_loss=1757.3502057212665\n","\tfinal_training_mse=[1.41783184 0.9780103 ]\n","\tfinal_training_mae=[1.01050726 0.98665788]\n","\tfinal_validating_mse=[1.48435245 0.97683185]\n","\tfinal_validating_mae=[1.05206754 0.98638772]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(12/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_8th.npz) starts training.\n","\n","iters=100,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.63 sec\n","iters=200,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.33 sec\n","iters=300,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.05 sec\n","iters=400,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.78 sec\n","iters=500,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.53 sec\n","iters=600,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.29 sec\n","iters=700,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.06 sec\n","iters=800,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.84 sec\n","iters=900,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.64 sec\n","iters=1000,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.46 sec\n","iters=1100,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.30 sec\n","iters=1200,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.15 sec\n","iters=1300,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.02 sec\n","iters=1400,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.91 sec\n","iters=1500,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.79 sec\n","iters=1600,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.66 sec\n","iters=1700,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.51 sec\n","iters=1800,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.34 sec\n","iters=1900,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.16 sec\n","iters=2000,loss=1750.037307968542,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.96 sec\n","----------\n","\ttraining_time=61.96 sec\n","\tepochs=2000\n","\tfinal_loss=1750.037307968542\n","\tfinal_training_mse=[1.4084372  0.97743507]\n","\tfinal_training_mae=[1.01034677 0.98643271]\n","\tfinal_validating_mse=[1.56890422 0.98200889]\n","\tfinal_validating_mae=[1.05351191 0.98841423]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(13/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_9th.npz) starts training.\n","\n","iters=100,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.56 sec\n","iters=200,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.26 sec\n","iters=300,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 13.98 sec\n","iters=400,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.70 sec\n","iters=500,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.45 sec\n","iters=600,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.20 sec\n","iters=700,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 24.97 sec\n","iters=800,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.74 sec\n","iters=900,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.53 sec\n","iters=1000,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.34 sec\n","iters=1100,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.17 sec\n","iters=1200,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.02 sec\n","iters=1300,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 41.88 sec\n","iters=1400,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.76 sec\n","iters=1500,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.63 sec\n","iters=1600,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.49 sec\n","iters=1700,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.35 sec\n","iters=1800,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.21 sec\n","iters=1900,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.02 sec\n","iters=2000,loss=1750.3193000112592,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.83 sec\n","----------\n","\ttraining_time=61.83 sec\n","\tepochs=2000\n","\tfinal_loss=1750.3193000112592\n","\tfinal_training_mse=[1.40857078 0.97768593]\n","\tfinal_training_mae=[1.0089599  0.98648569]\n","\tfinal_validating_mse=[1.56770195 0.97975113]\n","\tfinal_validating_mae=[1.06599383 0.98793735]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(14/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","\n","model(lambda_800_fold_10_10th.npz) starts training.\n","\n","iters=100,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 8.65 sec\n","iters=200,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 11.36 sec\n","iters=300,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 14.07 sec\n","iters=400,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 16.80 sec\n","iters=500,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 19.54 sec\n","iters=600,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 22.29 sec\n","iters=700,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 25.07 sec\n","iters=800,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 27.85 sec\n","iters=900,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 30.64 sec\n","iters=1000,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 33.46 sec\n","iters=1100,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 36.29 sec\n","iters=1200,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 39.14 sec\n","iters=1300,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 42.01 sec\n","iters=1400,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 44.89 sec\n","iters=1500,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 47.76 sec\n","iters=1600,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 50.62 sec\n","iters=1700,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 53.47 sec\n","iters=1800,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 56.30 sec\n","iters=1900,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 59.12 sec\n","iters=2000,loss=1770.4119888788382,lr=0.2,line search 0.02 sec,iteration 0.02 sec. Elapsed 61.91 sec\n","----------\n","\ttraining_time=61.91 sec\n","\tepochs=2000\n","\tfinal_loss=1770.4119888788382\n","\tfinal_training_mse=[1.43713451 0.9765151 ]\n","\tfinal_training_mae=[1.02019785 0.98591539]\n","\tfinal_validating_mse=[1.31062841 0.99028861]\n","\tfinal_validating_mae=[0.96485223 0.9930701 ]\n","\tfinal_learning_rate=0.2\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(15/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_1th.npz) starts training.\n","\n","iters=100,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.53 sec\n","iters=200,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.15 sec\n","iters=300,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.78 sec\n","iters=400,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.42 sec\n","iters=500,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.06 sec\n","iters=600,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.71 sec\n","iters=700,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.37 sec\n","iters=800,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.03 sec\n","iters=900,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.69 sec\n","iters=1000,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.36 sec\n","iters=1100,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.03 sec\n","iters=1200,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.71 sec\n","iters=1300,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.39 sec\n","iters=1400,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.08 sec\n","iters=1500,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 30.78 sec\n","iters=1600,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.49 sec\n","iters=1700,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.20 sec\n","iters=1800,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 35.93 sec\n","iters=1900,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 37.65 sec\n","iters=2000,loss=1744.7436181653284,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.39 sec\n","----------\n","\ttraining_time=39.39 sec\n","\tepochs=2000\n","\tfinal_loss=1744.7436181653284\n","\tfinal_training_mse=[1.39947639 0.97917885]\n","\tfinal_training_mae=[1.0055203  0.98731839]\n","\tfinal_validating_mse=[1.64955149 0.96631486]\n","\tfinal_validating_mae=[1.09695016 0.98044313]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(16/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_2th.npz) starts training.\n","\n","iters=100,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.54 sec\n","iters=200,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.20 sec\n","iters=300,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.85 sec\n","iters=400,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.52 sec\n","iters=500,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.19 sec\n","iters=600,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.87 sec\n","iters=700,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.56 sec\n","iters=800,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.25 sec\n","iters=900,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.96 sec\n","iters=1000,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.67 sec\n","iters=1100,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.39 sec\n","iters=1200,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.12 sec\n","iters=1300,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.86 sec\n","iters=1400,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.60 sec\n","iters=1500,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.34 sec\n","iters=1600,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 33.09 sec\n","iters=1700,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.84 sec\n","iters=1800,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.59 sec\n","iters=1900,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.34 sec\n","iters=2000,loss=1769.850782480567,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 40.08 sec\n","----------\n","\ttraining_time=40.08 sec\n","\tepochs=2000\n","\tfinal_loss=1769.850782480567\n","\tfinal_training_mse=[1.43448315 0.97840135]\n","\tfinal_training_mae=[1.01987408 0.98689842]\n","\tfinal_validating_mse=[1.33449066 0.97331233]\n","\tfinal_validating_mae=[0.96776614 0.98422286]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.07 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(17/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_3th.npz) starts training.\n","\n","iters=100,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.57 sec\n","iters=200,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.21 sec\n","iters=300,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.85 sec\n","iters=400,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.51 sec\n","iters=500,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.17 sec\n","iters=600,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.83 sec\n","iters=700,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.50 sec\n","iters=800,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.17 sec\n","iters=900,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.85 sec\n","iters=1000,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.53 sec\n","iters=1100,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.23 sec\n","iters=1200,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.93 sec\n","iters=1300,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.64 sec\n","iters=1400,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.36 sec\n","iters=1500,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.08 sec\n","iters=1600,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.82 sec\n","iters=1700,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.56 sec\n","iters=1800,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.30 sec\n","iters=1900,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.05 sec\n","iters=2000,loss=1771.6701099475658,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.80 sec\n","----------\n","\ttraining_time=39.80 sec\n","\tepochs=2000\n","\tfinal_loss=1771.6701099475658\n","\tfinal_training_mse=[1.43681479 0.97855005]\n","\tfinal_training_mae=[1.01413759 0.98692025]\n","\tfinal_validating_mse=[1.31350585 0.9719741 ]\n","\tfinal_validating_mae=[1.01939457 0.98402636]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.03 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(18/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_4th.npz) starts training.\n","\n","iters=100,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.61 sec\n","iters=200,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.25 sec\n","iters=300,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.90 sec\n","iters=400,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.55 sec\n","iters=500,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.21 sec\n","iters=600,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.88 sec\n","iters=700,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.55 sec\n","iters=800,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.23 sec\n","iters=900,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.91 sec\n","iters=1000,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.60 sec\n","iters=1100,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.31 sec\n","iters=1200,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.02 sec\n","iters=1300,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.74 sec\n","iters=1400,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.47 sec\n","iters=1500,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.20 sec\n","iters=1600,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.95 sec\n","iters=1700,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.70 sec\n","iters=1800,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.45 sec\n","iters=1900,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.21 sec\n","iters=2000,loss=1775.220076023776,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.96 sec\n","----------\n","\ttraining_time=39.96 sec\n","\tepochs=2000\n","\tfinal_loss=1775.220076023776\n","\tfinal_training_mse=[1.44271243 0.97749218]\n","\tfinal_training_mae=[1.02251705 0.98643315]\n","\tfinal_validating_mse=[1.26042716 0.98149493]\n","\tfinal_validating_mae=[0.94397941 0.98841025]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(19/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_5th.npz) starts training.\n","\n","iters=100,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.57 sec\n","iters=200,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.22 sec\n","iters=300,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.86 sec\n","iters=400,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.52 sec\n","iters=500,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.18 sec\n","iters=600,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.84 sec\n","iters=700,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.51 sec\n","iters=800,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.19 sec\n","iters=900,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.87 sec\n","iters=1000,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.56 sec\n","iters=1100,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.26 sec\n","iters=1200,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.97 sec\n","iters=1300,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.68 sec\n","iters=1400,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.41 sec\n","iters=1500,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.14 sec\n","iters=1600,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.88 sec\n","iters=1700,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.63 sec\n","iters=1800,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.38 sec\n","iters=1900,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.14 sec\n","iters=2000,loss=1776.4991815933558,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.90 sec\n","----------\n","\ttraining_time=39.90 sec\n","\tepochs=2000\n","\tfinal_loss=1776.4991815933558\n","\tfinal_training_mse=[1.44383021 0.97811823]\n","\tfinal_training_mae=[1.020405   0.98677733]\n","\tfinal_validating_mse=[1.25036711 0.97586043]\n","\tfinal_validating_mae=[0.96298789 0.98531263]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.11 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(20/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","model(lambda_9000_fold_10_5th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_6th.npz) starts training.\n","\n","iters=100,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.59 sec\n","iters=200,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.24 sec\n","iters=300,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.88 sec\n","iters=400,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.53 sec\n","iters=500,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.19 sec\n","iters=600,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.85 sec\n","iters=700,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.52 sec\n","iters=800,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.20 sec\n","iters=900,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.88 sec\n","iters=1000,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.57 sec\n","iters=1100,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.27 sec\n","iters=1200,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.97 sec\n","iters=1300,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.68 sec\n","iters=1400,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.41 sec\n","iters=1500,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.13 sec\n","iters=1600,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.87 sec\n","iters=1700,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.62 sec\n","iters=1800,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.37 sec\n","iters=1900,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.13 sec\n","iters=2000,loss=1755.3279651189214,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.88 sec\n","----------\n","\ttraining_time=39.88 sec\n","\tepochs=2000\n","\tfinal_loss=1755.3279651189214\n","\tfinal_training_mse=[1.4155477  0.97753746]\n","\tfinal_training_mae=[1.01416708 0.9864694 ]\n","\tfinal_validating_mse=[1.50490969 0.98108737]\n","\tfinal_validating_mae=[1.0191292  0.98808397]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.02 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(21/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","model(lambda_9000_fold_10_5th.npz) has already been trained.\n","model(lambda_9000_fold_10_6th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_7th.npz) starts training.\n","\n","iters=100,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.63 sec\n","iters=200,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.27 sec\n","iters=300,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.91 sec\n","iters=400,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.57 sec\n","iters=500,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.23 sec\n","iters=600,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.89 sec\n","iters=700,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.56 sec\n","iters=800,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.24 sec\n","iters=900,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.92 sec\n","iters=1000,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.61 sec\n","iters=1100,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.31 sec\n","iters=1200,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 26.02 sec\n","iters=1300,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.73 sec\n","iters=1400,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.45 sec\n","iters=1500,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.19 sec\n","iters=1600,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.93 sec\n","iters=1700,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.68 sec\n","iters=1800,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.42 sec\n","iters=1900,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.18 sec\n","iters=2000,loss=1757.3502057212665,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.93 sec\n","----------\n","\ttraining_time=39.93 sec\n","\tepochs=2000\n","\tfinal_loss=1757.3502057212665\n","\tfinal_training_mse=[1.41783184 0.9780103 ]\n","\tfinal_training_mae=[1.01050726 0.98665788]\n","\tfinal_validating_mse=[1.48435245 0.97683185]\n","\tfinal_validating_mae=[1.05206754 0.98638772]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.11 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(22/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","model(lambda_9000_fold_10_5th.npz) has already been trained.\n","model(lambda_9000_fold_10_6th.npz) has already been trained.\n","model(lambda_9000_fold_10_7th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_8th.npz) starts training.\n","\n","iters=100,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.51 sec\n","iters=200,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.16 sec\n","iters=300,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.80 sec\n","iters=400,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.46 sec\n","iters=500,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.12 sec\n","iters=600,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.78 sec\n","iters=700,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.46 sec\n","iters=800,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.13 sec\n","iters=900,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.81 sec\n","iters=1000,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.50 sec\n","iters=1100,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.20 sec\n","iters=1200,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.91 sec\n","iters=1300,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.62 sec\n","iters=1400,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.34 sec\n","iters=1500,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.08 sec\n","iters=1600,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.81 sec\n","iters=1700,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.55 sec\n","iters=1800,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.30 sec\n","iters=1900,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.05 sec\n","iters=2000,loss=1750.037307968542,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.80 sec\n","----------\n","\ttraining_time=39.80 sec\n","\tepochs=2000\n","\tfinal_loss=1750.037307968542\n","\tfinal_training_mse=[1.4084372  0.97743507]\n","\tfinal_training_mae=[1.01034677 0.98643271]\n","\tfinal_validating_mse=[1.56890422 0.98200889]\n","\tfinal_validating_mae=[1.05351191 0.98841423]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.09 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(23/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","model(lambda_9000_fold_10_5th.npz) has already been trained.\n","model(lambda_9000_fold_10_6th.npz) has already been trained.\n","model(lambda_9000_fold_10_7th.npz) has already been trained.\n","model(lambda_9000_fold_10_8th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_9th.npz) starts training.\n","\n","iters=100,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.53 sec\n","iters=200,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.18 sec\n","iters=300,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.82 sec\n","iters=400,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.48 sec\n","iters=500,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.13 sec\n","iters=600,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 15.79 sec\n","iters=700,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.46 sec\n","iters=800,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.14 sec\n","iters=900,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.82 sec\n","iters=1000,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.50 sec\n","iters=1100,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.20 sec\n","iters=1200,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.90 sec\n","iters=1300,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.61 sec\n","iters=1400,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.32 sec\n","iters=1500,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.05 sec\n","iters=1600,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.78 sec\n","iters=1700,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.52 sec\n","iters=1800,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.27 sec\n","iters=1900,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.02 sec\n","iters=2000,loss=1750.3193000112592,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.77 sec\n","----------\n","\ttraining_time=39.77 sec\n","\tepochs=2000\n","\tfinal_loss=1750.3193000112592\n","\tfinal_training_mse=[1.40857078 0.97768593]\n","\tfinal_training_mae=[1.0089599  0.98648569]\n","\tfinal_validating_mse=[1.56770195 0.97975113]\n","\tfinal_validating_mae=[1.06599383 0.98793735]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","11.01 GiB memory has been used!\n","Memory limit exceeds. Suicides now!\n","Trying to restart...\n","\n","\n","\n","\n","(24/100)th restart\n","--------\n","model(lambda_700_fold_10_1th.npz) has already been trained.\n","model(lambda_700_fold_10_2th.npz) has already been trained.\n","model(lambda_700_fold_10_3th.npz) has already been trained.\n","model(lambda_700_fold_10_4th.npz) has already been trained.\n","model(lambda_700_fold_10_5th.npz) has already been trained.\n","model(lambda_700_fold_10_6th.npz) has already been trained.\n","model(lambda_700_fold_10_7th.npz) has already been trained.\n","model(lambda_700_fold_10_8th.npz) has already been trained.\n","model(lambda_700_fold_10_9th.npz) has already been trained.\n","model(lambda_700_fold_10_10th.npz) has already been trained.\n","model(lambda_800_fold_10_1th.npz) has already been trained.\n","model(lambda_800_fold_10_2th.npz) has already been trained.\n","model(lambda_800_fold_10_3th.npz) has already been trained.\n","model(lambda_800_fold_10_4th.npz) has already been trained.\n","model(lambda_800_fold_10_5th.npz) has already been trained.\n","model(lambda_800_fold_10_6th.npz) has already been trained.\n","model(lambda_800_fold_10_7th.npz) has already been trained.\n","model(lambda_800_fold_10_8th.npz) has already been trained.\n","model(lambda_800_fold_10_9th.npz) has already been trained.\n","model(lambda_800_fold_10_10th.npz) has already been trained.\n","model(lambda_9000_fold_10_1th.npz) has already been trained.\n","model(lambda_9000_fold_10_2th.npz) has already been trained.\n","model(lambda_9000_fold_10_3th.npz) has already been trained.\n","model(lambda_9000_fold_10_4th.npz) has already been trained.\n","model(lambda_9000_fold_10_5th.npz) has already been trained.\n","model(lambda_9000_fold_10_6th.npz) has already been trained.\n","model(lambda_9000_fold_10_7th.npz) has already been trained.\n","model(lambda_9000_fold_10_8th.npz) has already been trained.\n","model(lambda_9000_fold_10_9th.npz) has already been trained.\n","\n","model(lambda_9000_fold_10_10th.npz) starts training.\n","\n","iters=100,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 7.56 sec\n","iters=200,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 9.21 sec\n","iters=300,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 10.85 sec\n","iters=400,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 12.51 sec\n","iters=500,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 14.17 sec\n","iters=600,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.02 sec. Elapsed 15.84 sec\n","iters=700,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 17.52 sec\n","iters=800,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 19.20 sec\n","iters=900,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 20.89 sec\n","iters=1000,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 22.58 sec\n","iters=1100,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 24.28 sec\n","iters=1200,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 25.99 sec\n","iters=1300,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 27.71 sec\n","iters=1400,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 29.43 sec\n","iters=1500,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 31.16 sec\n","iters=1600,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 32.90 sec\n","iters=1700,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 34.65 sec\n","iters=1800,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 36.40 sec\n","iters=1900,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 38.15 sec\n","iters=2000,loss=1770.4119888788382,lr=0.8,line search 0.01 sec,iteration 0.01 sec. Elapsed 39.90 sec\n","----------\n","\ttraining_time=39.90 sec\n","\tepochs=2000\n","\tfinal_loss=1770.4119888788382\n","\tfinal_training_mse=[1.43713451 0.9765151 ]\n","\tfinal_training_mae=[1.02019785 0.98591539]\n","\tfinal_validating_mse=[1.31062841 0.99028861]\n","\tfinal_validating_mae=[0.96485223 0.9930701 ]\n","\tfinal_learning_rate=0.8\n","----------\n","\n","\n","\n","\n","Best model(lambda=800) starts training.\n","\n"]}]}]}